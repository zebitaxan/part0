T√≠tulo: Sistema IA de generaci√≥n de perfiles laborales desde respuestas empresariales

üß© Contexto del proyecto

Estamos construyendo un sistema de reclutamiento inteligente.
Las empresas completan un cuestionario interactivo sobre un puesto de trabajo.
A partir de esas respuestas, la IA debe generar un perfil ideal del puesto:
una representaci√≥n num√©rica (vector) que indica la importancia de distintas competencias o habilidades.

Ejemplo de resultado esperado:

{
  "Comunicaci√≥n": 0.9,
  "Persuasi√≥n": 1.0,
  "Resiliencia": 0.8,
  "Empat√≠a": 0.6,
  "Organizaci√≥n": 0.7
}


Ese vector servir√° luego para comparar con perfiles de candidatos.

‚öôÔ∏è Objetivo t√©cnico

Desarrollar un servicio (API o m√≥dulo local) que:

Reciba respuestas de texto y selecci√≥n de una empresa.

Analice sem√°nticamente el texto (NLP / embeddings).

Compare las palabras clave con una base interna de competencias laborales.

Asigne pesos a cada competencia seg√∫n:

Frecuencia y contexto de aparici√≥n.

Relevancia sem√°ntica.

Preguntas de prioridad respondidas por la empresa.

Devuelva un JSON estructurado con el perfil ideal del puesto.

üß† Flujo de datos

Input (respuestas de empresa):

{
  "descripcion": "Buscamos un comercial B2B con buena comunicaci√≥n, persistente y enfocado en resultados.",
  "prioridades": ["Cierre de ventas", "Comunicaci√≥n", "Resiliencia"]
}


Procesamiento IA:

Limpieza del texto

Tokenizaci√≥n

Extracci√≥n de keywords

Comparaci√≥n con base de competencias

Calculo de pesos (ponderaci√≥n)

Output:

{
  "Cierre de ventas": 1.0,
  "Comunicaci√≥n": 0.9,
  "Resiliencia": 0.8,
  "Empat√≠a": 0.6
}

üß© Estructura del proyecto sugerida
/src
  ‚îú‚îÄ‚îÄ main.py                  # Entrada principal del programa o API
  ‚îú‚îÄ‚îÄ analyzer/
  ‚îÇ    ‚îú‚îÄ‚îÄ text_cleaner.py     # Limpieza y normalizaci√≥n del texto
  ‚îÇ    ‚îú‚îÄ‚îÄ keyword_extractor.py# Extracci√≥n de t√©rminos clave
  ‚îÇ    ‚îú‚îÄ‚îÄ embedding_matcher.py# Similitud sem√°ntica con base de competencias
  ‚îÇ    ‚îî‚îÄ‚îÄ weight_assigner.py  # Asignaci√≥n de pesos
  ‚îú‚îÄ‚îÄ data/
  ‚îÇ    ‚îî‚îÄ‚îÄ skills_base.json    # Base de competencias (nombre, keywords, categor√≠a)
  ‚îú‚îÄ‚îÄ utils/
  ‚îÇ    ‚îî‚îÄ‚îÄ text_utils.py       # Funciones auxiliares
  ‚îî‚îÄ‚îÄ requirements.txt

üß∞ Stack tecnol√≥gico sugerido

Lenguaje: Python 3.11+

Bibliotecas:

sentence-transformers ‚Üí para embeddings sem√°nticos

scikit-learn ‚Üí para similitud coseno

numpy, pandas ‚Üí manejo de datos

fastapi o flask ‚Üí para exponer la API

nltk o spacy ‚Üí procesamiento de texto

üí° Ejemplo de l√≥gica interna (pseudoc√≥digo)
def generar_perfil_puesto(respuestas, base_competencias):
    texto = limpiar_texto(respuestas["descripcion"])
    keywords = extraer_keywords(texto)
    prioridades = respuestas.get("prioridades", [])

    perfil = {}
    for skill in base_competencias:
        similitud = similitud_semantica(skill["keywords"], keywords)
        peso_base = similitud
        if skill["nombre"] in prioridades:
            peso_base += 0.2  # ajuste si fue prioridad
        perfil[skill["nombre"]] = round(min(peso_base, 1.0), 2)

    return perfil

üìö Ejemplo de base de competencias (skills_base.json)
[
  {
    "nombre": "Comunicaci√≥n",
    "keywords": ["hablar", "presentar", "explicar", "comunicar", "expresi√≥n"],
    "categoria": "interpersonal"
  },
  {
    "nombre": "Cierre de ventas",
    "keywords": ["negociar", "cerrar", "clientes", "ventas", "convencer"],
    "categoria": "t√©cnica"
  },
  {
    "nombre": "Resiliencia",
    "keywords": ["persistente", "insistente", "no se rinde", "superar rechazo"],
    "categoria": "personal"
  },
  {
    "nombre": "Empat√≠a",
    "keywords": ["comprender", "cliente", "emociones", "escuchar"],
    "categoria": "interpersonal"
  },
  {
    "nombre": "Organizaci√≥n",
    "keywords": ["planificar", "orden", "seguimiento", "agenda"],
    "categoria": "cognitiva"
  }
]

üöÄ Tareas que Copilot debe generar

C√≥digo de inicializaci√≥n y carga de la base de competencias.

Funci√≥n para limpiar texto (quitar stopwords, normalizar, etc.).

Funci√≥n para extraer keywords del texto (TF-IDF o spaCy).

Funci√≥n para calcular similitud entre keywords y base de competencias usando embeddings.

Funci√≥n de ponderaci√≥n final y normalizaci√≥n de pesos (0‚Äì1).

Endpoint /generar_perfil en FastAPI que reciba JSON de respuestas y devuelva el perfil generado.

Pruebas unitarias b√°sicas con pytest.

‚úÖ Entrega esperada

C√≥digo funcional y modular.

F√°cil de integrar con un motor de matching de candidatos.

Capaz de interpretar texto en espa√±ol e ingl√©s.

Resultados en formato JSON estructurado y legible.

¬øQuieres que te lo deje tambi√©n en formato .md (Markdown) o .txt listo para copiar y subir a tu repositorio como SPEC_PERFIL_AI.md para que Copilot lo interprete con m√°s contexto?
As√≠ puedes usarlo directamente como documento base de desarrollo.

Perfecto üòé
Aqu√≠ tienes un prompt/documento listo para usar en GitHub Copilot (o cualquier copiloto de IA de desarrollo) que puedes pegar directamente en tu entorno (por ejemplo, VS Code o Cursor).

Este prompt est√° estructurado para guiar a Copilot a generar el prototipo del motor de perfilado y matching de talento, con claridad sobre la arquitectura, l√≥gica, datos y ejemplos.

üß† PROMPT DOCUMENTO ‚Äî Talent Matching AI System Blueprint
# üéØ Proyecto: Talent Match AI System
## Descripci√≥n general
Queremos crear un sistema que reciba respuestas de una empresa (texto y opciones) y devuelva un **perfil de puesto ideal** expresado como un vector de habilidades con pesos num√©ricos.
Luego, ese vector podr√° ser comparado con los vectores de los candidatos para determinar qu√© tan compatible es cada uno con el puesto.

---

## üß© Objetivos principales
1. Analizar las respuestas textuales de la empresa para **extraer competencias y rasgos clave**.
2. Mapear esos rasgos a una **base est√°ndar de habilidades**.
3. Asignar pesos din√°micos seg√∫n la importancia percibida.
4. Generar un **perfil final del puesto** (diccionario tipo `{habilidad: peso}`).
5. Permitir comparar ese perfil con los de los candidatos usando una m√©trica de similitud.

---

## ‚öôÔ∏è Arquitectura recomendada

### 1. Input
Archivo o formulario JSON con respuestas de la empresa:
```json
{
  "objetivo_puesto": "Aumentar las ventas B2B en un 30% anual",
  "responsabilidades": "Contactar clientes, cerrar negociaciones, manejar objeciones",
  "autonomia": "Alta",
  "trabajo_equipo": "Moderado",
  "descripcion_candidato_ideal": "Alguien persistente, con buena comunicaci√≥n y gran energ√≠a para cerrar clientes dif√≠ciles",
  "prioridades": ["Cierre de ventas", "Comunicaci√≥n", "Resiliencia", "Organizaci√≥n"]
}

2. Procesamiento (pipeline principal)
a) Limpieza y tokenizaci√≥n del texto

Convertir a min√∫sculas

Eliminar signos, stopwords, etc.

Extraer palabras clave

b) M√≥dulo NLP para extracci√≥n sem√°ntica

Usar modelo de embeddings (sentence-transformers, OpenAI embeddings, etc.)

Comparar cada token con una base de competencias laborales

Seleccionar las m√°s cercanas (cosine similarity > 0.7)

c) Asignaci√≥n de pesos

Base: frecuencia o relevancia del t√©rmino

Ajustes:

Si est√° en la lista de ‚Äúprioridades‚Äù ‚Üí +0.2

Si aparece m√°s de una vez ‚Üí +0.1

Si tiene sin√≥nimos relevantes ‚Üí +0.05

Limitar pesos entre 0.0 y 1.0

d) Generaci√≥n del vector del perfil

Ejemplo de salida:

{
  "Cierre de ventas": 1.0,
  "Comunicaci√≥n": 0.9,
  "Resiliencia": 0.8,
  "Organizaci√≥n": 0.7,
  "Empat√≠a": 0.6
}

3. Base de competencias (ejemplo inicial)
competencias = {
    "Comunicaci√≥n": ["hablar", "presentar", "escuchar", "argumentar"],
    "Cierre de ventas": ["negociar", "cerrar", "convencer", "ventas"],
    "Resiliencia": ["persistencia", "no rendirse", "resistencia", "reintento"],
    "Empat√≠a": ["entender", "cliente", "emociones", "ponerse en el lugar"],
    "Organizaci√≥n": ["planificar", "seguimiento", "orden", "metodolog√≠a"]
}


Copilot debe:

Crear una funci√≥n get_closest_competencies(text, competencias) que calcule la similitud entre el texto y cada lista de sin√≥nimos usando embeddings.

Retornar las m√°s cercanas con sus puntajes.

4. Motor de Matching

Crear una funci√≥n calculate_match(perfil_empresa, perfil_candidato) usando similitud del coseno:

from numpy import dot
from numpy.linalg import norm

def calculate_match(perfil_empresa, perfil_candidato):
    keys = set(perfil_empresa.keys()) | set(perfil_candidato.keys())
    v1 = [perfil_empresa.get(k, 0) for k in keys]
    v2 = [perfil_candidato.get(k, 0) for k in keys]
    return dot(v1, v2) / (norm(v1) * norm(v2))


Resultado ‚Üí valor entre 0 y 1 (1 = match perfecto)

üßÆ Flujo completo en pseudoc√≥digo
text = load_responses("empresa.json")
competencias_base = load_competencias()

tokens = clean_and_tokenize(text)
matched_competencias = get_closest_competencies(tokens, competencias_base)
perfil = assign_weights(matched_competencias, prioridades)
save_profile(perfil, "perfil_empresa.json")

# Ejemplo de matching
candidato = load_profile("perfil_candidato.json")
score = calculate_match(perfil, candidato)
print(f"Compatibilidad: {score*100:.2f}%")

üß∞ Tecnolog√≠as recomendadas

Python 3.10+

openai o sentence-transformers (para embeddings)

numpy para operaciones vectoriales

json o pandas para manejar datos

fastapi o flask para crear un endpoint si se quiere servir por API

‚úÖ Entregable esperado

Copilot debe generar:

Un script Python llamado perfilador.py con:

Funci√≥n de extracci√≥n y similitud

Funci√≥n de asignaci√≥n de pesos

Funci√≥n de generaci√≥n del perfil

Un segundo script matching.py con:

Funci√≥n de similitud del coseno

Ejemplo pr√°ctico de comparaci√≥n entre empresa y candidato

üìò Notas para Copilot

Mant√©n el c√≥digo limpio, comentado y modular.

Aseg√∫rate de que los pesos finales est√©n normalizados (0.0‚Äì1.0).

Prioriza interpretabilidad sobre complejidad.

Los nombres de variables deben ser legibles en espa√±ol.

Incluye ejemplos de entrada/salida en los docstrings.
